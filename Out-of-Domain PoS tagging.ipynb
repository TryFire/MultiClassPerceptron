{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = json.load(open('corpus/fr/fr.gsd.train.json'))\n",
    "dev_set = json.load(open('corpus/fr/fr.gsd.dev.json'))\n",
    "test_set = json.load(open('corpus/fr/fr.gsd.test.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a vue on data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Les', 'commotions', 'cérébrales', 'sont', 'devenu', 'si', 'courantes', 'dans', 'ce', 'sport', \"qu'\", 'on', 'les', 'considére', 'presque', 'comme', 'la', 'routine', '.']\n",
      "['DET', 'NOUN', 'ADJ', 'AUX', 'VERB', 'ADV', 'ADJ', 'ADP', 'DET', 'NOUN', 'SCONJ', 'PRON', 'PRON', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "for k,v in train_set[:20]:\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing shortly the different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbr of sentences in train_set : 14450\n",
      "nbr of sentences in dev_set : 1476\n",
      "nbr of sentences in test_set : 416\n"
     ]
    }
   ],
   "source": [
    "# the data may be come from the newspaper\n",
    "\n",
    "# the number of sentences in each data_set\n",
    "print('nbr of sentences in train_set : %d'% len(train_set))\n",
    "print('nbr of sentences in dev_set : %d'% len(dev_set))\n",
    "print('nbr of sentences in test_set : %d'% len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three measures of the noisiness of a corpus\n",
    "\n",
    "- The percentage of **Out-of-Vocabulary (OOV) words**, i.e. words appearing in the test set that are not contained on the train set;\n",
    "- **[The KL divergence of 3-grams characters](https://aclweb.org/anthology/W16-3905)** distributions estimated on the train and test sets\n",
    "- perplexity on the test set of a (word level) Language Model estimated on the test\n",
    "set. The language model can be estimated by KenLM (this tools can also be used\n",
    "to compute the perpexlity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(data_set):\n",
    "    '''\n",
    "    data_set : input data in dimension of (N,M)\n",
    "    \n",
    "    return : the set of words appearing the data_set\n",
    "    '''\n",
    "    words = set()\n",
    "    for k,v in data_set:\n",
    "        words = words.union(k)\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The percentage of Out-of-Vocabulary (OOV) words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_train_set = extract_words(train_set)\n",
    "words_test_set = extract_words(test_set)\n",
    "oov = words_test_set.difference(words_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('percentage of oov in train_set : %.2f%%'%(len(oov)/len(words_train_set)*100))\n",
    "print('percentage of oov in test_set : %.2f%%'%(len(oov)/len(words_test_set)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:// The KL divergence of 3-grams characters distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we try to mesure the noisiness of a corpus, because the noisiness can do large impact on the performance of model. And a good knowledge can help us to build and train a better model.\n",
    "- here the metric gives a low value means that there are few noisiness in the corpus, else much noisiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:// compute the value of the different metric for the different combination of train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### Considering the features\n",
    "\n",
    "- **the word**  *explain : this feature can directly get the labels which are related to the word*\n",
    "#### *Windows*\n",
    "- **a window of 5 words around the word** of interest (i.e. the word we want to predict a label for, the two previous words and the two following words) *explain: these features can make the label more accurate*\n",
    "#### *Word features*\n",
    "In this section, we consider these sources of information equally important and normalize each of the four component vectors to unit length\n",
    "- **counts of left neighbors**\n",
    "- **counts of right neighbors**\n",
    "- **binary suffix features**\n",
    "- **binary shape features**\n",
    "#### *Distributional features*\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_window(i, context, l=2):\n",
    "    '''\n",
    "    i : the index of the word in the context\n",
    "    context : the sentence\n",
    "    l : a window of size is 2*l+1\n",
    "    \n",
    "    return : list of features which are tuple (feature_name, value)\n",
    "    '''\n",
    "    # the result of features\n",
    "    res = []\n",
    "    # the word\n",
    "    word = context[i]\n",
    "    # add the word to the list\n",
    "    res.append(word)\n",
    "    punct = [',','.','(',')',':',';','/','?','«','\"', '»']\n",
    "    if word in punct:\n",
    "        return res\n",
    "    for k in range(1,l+1):\n",
    "        # the word of index(word) - k\n",
    "        res.append('win_i-%d'%k + context[i-k] if i-k>=0 else 'none')\n",
    "        # the word of index(word) + k\n",
    "        res.append('win_i+%d'%k+context[i+k] if i+k<len(context) else 'none')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_suffix(i, context, s=3):\n",
    "    '''\n",
    "    i : the index of the word in the context\n",
    "    context : the sentence\n",
    "    s : the 1,2,...,s suffix lettre of the word\n",
    "    \n",
    "    return : list of features which are tuple (feature_name, value)\n",
    "    '''\n",
    "    \n",
    "    # the result of features\n",
    "    res = []\n",
    "    # the word\n",
    "    word = context[i]\n",
    "    for k in range(-1, -(s+1), -1):\n",
    "        # the feature of k-th suffix of the word\n",
    "        res.append('%d-th_suffix_'%k + word[k:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_shape(i, context):\n",
    "    '''\n",
    "    i : the index of the word in the context\n",
    "    context : the sentence\n",
    "    \n",
    "    return : list of features which are tuple (feature_name, value)\n",
    "    '''\n",
    "    def has_digit(s):\n",
    "        '''\n",
    "        check if a string has digit or nor\n",
    "        '''\n",
    "        return any(c.isdigit() for c in s)\n",
    "    \n",
    "    # the result of features\n",
    "    res = []\n",
    "    # the word\n",
    "    word = context[i]\n",
    "    \n",
    "    punct = [',','.','(',')',':',';','/','?','«','\"', '»']\n",
    "    if word in punct:\n",
    "        res.append('punct')\n",
    "        return res\n",
    "    \n",
    "    ## different orthographic\n",
    "    # banary feature indicating whether the word starts with a capital letter or not, 1:yes, 0:not\n",
    "    if word.istitle():\n",
    "        res.append('start_capital')\n",
    "    # banary feature indicating whether the word is made of all capital letters or not, 1:yes, 0:not\n",
    "    if word.isupper():\n",
    "        res.append('only_capital')\n",
    "    # banary feature indicating whether the word has a digit or not, 1:yes, 0:not\n",
    "    if has_digit(word):\n",
    "        res.append('has_digit')\n",
    "    # banary feature indicating whether the word has a hyphen or not, 1:yes, 0:not\n",
    "    if '-' in word:\n",
    "        res.append('has_hyphen')\n",
    "    # banary feature indicating whether the word has a low hyphen or not, 1:yes, 0:not\n",
    "    if '_' in word:\n",
    "        res.append('has_hyphen_low')\n",
    "    # banary feature indicating whether the letters in the word are all alphanumeric or not, 1:yes, 0:not\n",
    "    if not word.isalnum():\n",
    "        res.append('not_alnum')\n",
    "    # binary feature indicating whether the length of word is more than 3\n",
    "#     if len(word) > 3:\n",
    "#         res.append('word_len_>_3')\n",
    "    \n",
    "    if '\\'' in word:\n",
    "        res.append('abbr')\n",
    "    \n",
    "    ## different morphological\n",
    "    # aient \n",
    "    \n",
    "    ## \n",
    "    # son sa ser ton \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_distribution(data, freq = 100):\n",
    "    freq_bigram_left = defaultdict(lambda: defaultdict(int))\n",
    "    freq_bigram_right = defaultdict(lambda: defaultdict(int))\n",
    "    for words, labels in data:\n",
    "        for i in range(len(words)):\n",
    "            if i > 0:\n",
    "                freq_bigram_left[words[i]][words[i-1]] += 1\n",
    "            else :\n",
    "                freq_bigram_left[words[i]]['none'] += 1\n",
    "            if i < len(words)-1:\n",
    "                freq_bigram_right[words[i]][words[i+1]] += 1\n",
    "    for word, counts in freq_bigram_left.items():\n",
    "        freq_bigram_left[word] = list(sorted(counts.items(), key=lambda x : x[1], reverse=True))[:freq]\n",
    "    for word, counts in freq_bigram_right.items():\n",
    "        freq_bigram_right[word] = list(sorted(counts.items(), key=lambda x : x[1], reverse=True))[:freq]\n",
    "    return freq_bigram_left, freq_bigram_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(i, context, bigram_left, bigram_right):\n",
    "    res = feature_window(i, context)\n",
    "    res += feature_suffix(i, context)\n",
    "    res += feature_shape(i, context)\n",
    "#     for i in range(len(bigram_left)):\n",
    "#         res.append('%d-th_freq_left_'%i + bigram_left[i][0])\n",
    "#     for i in range(len(bigram_right)):\n",
    "#         res.append('%d-th_freq_right_'%i + bigram_right[i][0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data):\n",
    "    dataset = []\n",
    "    labelset = []\n",
    "    freq_bigram_left, freq_bigram_right = feature_distribution(data,freq=100)\n",
    "    for words, labels in data:\n",
    "        for i in range(len(words)):\n",
    "            dataset.append(extract_features(i, words, freq_bigram_left[words[i]], freq_bigram_right[words[i]]))\n",
    "            labelset.append(labels[i])\n",
    "    return dataset, labelset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, labels):\n",
    "        \n",
    "        self.labels = labels\n",
    "        # Each feature gets its own weight vector, with one weight for\n",
    "        # each possible label\n",
    "        self.weights = defaultdict(lambda: defaultdict(float))\n",
    "        # The accumulated values of the weight vector at the t-th\n",
    "        # iteration: sum_{i=1}^{n - 1} w_i\n",
    "        #\n",
    "        # The current value (w_t) is not yet added. The key of this\n",
    "        # dictionary is a pair (feature, label)\n",
    "        self._accum = defaultdict(int)\n",
    "        # The last time the feature was changed, for the averaging.\n",
    "        self._last_update = defaultdict(int)\n",
    "        # Number of examples seen\n",
    "        self.n_updates = 0\n",
    "\n",
    "    def predict(self, features):\n",
    "        '''Dot-product the features and current weights and return\n",
    "        the best class.'''\n",
    "        \n",
    "        # get the scores of all the labels based on the features\n",
    "        labels, labels_score = self.score(features)\n",
    "        # get the label whose socre is max\n",
    "        return labels[np.argmax(labels_score)]\n",
    "    \n",
    "    def predict_all(self, features):\n",
    "        '''\n",
    "        predict the labels based on the \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            - features, an iterable\n",
    "              WARNING: the `value' of the feature is always assumed to be 1.\n",
    "        \n",
    "        return : a list of babels predicted\n",
    "        '''\n",
    "        predicts = []\n",
    "#         fp = FloatProgress(min=0, max=len(features))\n",
    "#         display(fp)\n",
    "        for f in features:\n",
    "            predicts.append(self.predict(f))\n",
    "#             fp.value += 1\n",
    "        return predicts\n",
    "    \n",
    "    def fit(self, train_set, train_labels):\n",
    "        '''\n",
    "        Parameters\n",
    "            - train_set: an iterable of the features of all data\n",
    "            - train_labels : an iterable of labels \n",
    "        '''\n",
    "        f = FloatProgress(min=0, max=len(train_labels))\n",
    "        display(f)\n",
    "        for features, true_label in zip(train_set, train_labels):\n",
    "            f.value += 1\n",
    "            self.update(true_label, self.predict(features), features) \n",
    "        self.average_weights()\n",
    "            #self.average_weights()\n",
    "#             for i in range(2):\n",
    "#                 predict_lbl = self.predict(features)\n",
    "#                 if predict_lbl == true_label:\n",
    "#                     break\n",
    "#                 self.update(true_label, predict_lbl, features) \n",
    "    \n",
    "    def score(self, features, labels=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        - features, an iterable\n",
    "             a sequence of binary features. Each feature must be\n",
    "             hashable. WARNING: the `value' of the feature is always\n",
    "             assumed to be 1.\n",
    "        - labels, a subset of self.labels\n",
    "             if not None, the score is computed only for these labels\n",
    "        \"\"\" \n",
    "        if not labels:\n",
    "            # list of scores of the sum of weights associated with each label of all features\n",
    "            # where the index of this list is the index of list of all labels\n",
    "            labels_score = np.zeros(len(self.labels))\n",
    "            for f in features:\n",
    "                for label in self.labels:\n",
    "                    # get the weight associated by the feature and label\n",
    "                    # then add to the list of scores \n",
    "                    labels_score[self.labels.index(label)] += self.weights[f][label]\n",
    "            return self.labels, labels_score\n",
    "        else :\n",
    "            labels_score = np.zeros(len(labels))\n",
    "            for f in features:\n",
    "                for label in labels:\n",
    "                    labels_score[labels.index(label)] += self.weights[f][label]\n",
    "            return labels, labels_score\n",
    "        \n",
    "\n",
    "    def update(self, truth, guess, features):\n",
    "        '''\n",
    "        if the true label == predicted label, then do nothing \n",
    "        else for each feature, update the associated weights of all labels \n",
    "        '''\n",
    "        def upd_feat(label, feature, v):\n",
    "            param = (label, feature)\n",
    "            self._accum[param] += (self.n_updates -\n",
    "                                   self._last_update[param]) * self.weights[feature][label]\n",
    "            self._last_update[param] = self.n_updates\n",
    "            self.weights[feature][label] += v\n",
    "            \n",
    "        self.n_updates += 1\n",
    "\n",
    "        if truth == guess:\n",
    "            return\n",
    "\n",
    "        for f in features:\n",
    "            upd_feat(truth, f, 1.0)\n",
    "            upd_feat(guess, f, -1.0)\n",
    "\n",
    "    def average_weights(self):\n",
    "        \"\"\"\n",
    "        Average weights of the perceptron\n",
    "\n",
    "        Training can no longer be resumed.\n",
    "        \"\"\"\n",
    "        for feat, weights in self.weights.items():\n",
    "            new_feat_weights = defaultdict(float)\n",
    "            for label, w in weights.items():\n",
    "                param = (label, feat)\n",
    "                # Be careful not to add 1 to take into account the\n",
    "                # last weight vector (without increasing the number of\n",
    "                # iterations in the averaging)\n",
    "                total = self._accum[param] + \\\n",
    "                    (self.n_updates + 1 - self._last_update[param]) * w\n",
    "                averaged = round(total / self.n_updates, 3)\n",
    "                if averaged:\n",
    "                    new_feat_weights[label] = averaged\n",
    "            self.weights[feat] = new_feat_weights\n",
    "    \n",
    "    def evaluate(self, test_set, test_labels):\n",
    "        import numpy as np\n",
    "        predict_labels = self.predict_all(test_set)\n",
    "        num_true = np.sum(np.array(predict_labels) == np.array(test_labels))\n",
    "        num_tatol = len(test_labels)\n",
    "        accuracy = num_true/num_tatol\n",
    "        print('true_num: %d    total_num: %d ======> accuracy : %.4f%%'%(num_true, num_tatol, accuracy*100))\n",
    "        return predict_labels\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    def __getstate__(self):\n",
    "        \"\"\"\n",
    "        Serialization of a perceptron\n",
    "\n",
    "        We are only serializing the weight vector as a dictionnary\n",
    "        because defaultdict with lambda can not be serialized.\n",
    "        \"\"\"\n",
    "        # should we also serialize the other attributes to allow\n",
    "        # learning to continue?\n",
    "        return {\"weights\": {k: v for k, v in self.weights.items()}}\n",
    "\n",
    "    def __setstate__(self, data):\n",
    "        \"\"\"\n",
    "        De-serialization of a perceptron\n",
    "        \"\"\"\n",
    "\n",
    "        self.weights = defaultdict(lambda: defaultdict(float), data[\"weights\"])\n",
    "        # ensure we are no longer able to continue training\n",
    "        self._accum = None\n",
    "        self._last_update = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_lables(data_set):\n",
    "    res = set()\n",
    "    for words, labels in data_set:\n",
    "        res = res | set(labels)\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_lables(train_set)\n",
    "train_dataset, train_labels = build_dataset(train_set)\n",
    "test_dataset, test_labels = build_dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['et',\n",
       " 'win_i-1médecins',\n",
       " 'win_i+1scientifiques',\n",
       " 'win_i-2de',\n",
       " 'win_i+2fous',\n",
       " '-1-th_suffix_t',\n",
       " '-2-th_suffix_et',\n",
       " '-3-th_suffix_et']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Perceptron(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14b28f68e284ae3a5650f93eba5154e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=345009.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.fit(train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.average_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_num: 9237    total_num: 9742 ======> accuracy : 94.8163%\n"
     ]
    }
   ],
   "source": [
    "predicts = p.evaluate(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_num: 9727    total_num: 10000 ======> accuracy : 97.2700%\n"
     ]
    }
   ],
   "source": [
    "predicts_train_lanels = p.evaluate(train_dataset[:10000], train_labels[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bigram_left, freq_bigram_right = feature_distribution(train_set, freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Les', 1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_bigram_left['commotions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(data, filename):\n",
    "    import pickle \n",
    "    with open(filename, 'w')as fp:\n",
    "        json.dump(data, fp)\n",
    "\n",
    "weights = p.__getstate__()\n",
    "save_model(weights, 'accuracy_94.81%_without_df_mymodel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "wrong = np.array(test_dataset)[np.array(predicts) != np.array(test_labels)]\n",
    "wrong_label = np.array(test_labels) [np.array(predicts) != np.array(test_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3406\n",
      "et\n",
      "les\n",
      "et\n",
      "scientifiques\n",
      "fous\n",
      "que\n",
      "avons\n",
      "vus\n",
      "pourrions\n",
      "un\n",
      "autre\n",
      "pour\n",
      "l'\n",
      "à\n",
      "de\n",
      "du\n",
      "été\n",
      "largement\n",
      "que\n",
      "du\n",
      "non\n",
      "du\n",
      "est\n",
      "de\n",
      "diverses\n",
      "aux\n",
      "comme\n",
      "la\n",
      "les\n",
      "et\n",
      "les\n",
      "l'\n",
      "dans\n",
      "__DIGIT__\n",
      "par\n",
      "de\n",
      "1er\n",
      "l'\n",
      "Organisation\n",
      "la\n",
      "Sécurité\n",
      "et\n",
      "la\n",
      "Coopération\n",
      "en\n",
      "jusqu'\n",
      "au\n",
      "avant\n",
      "l'\n",
      "et\n",
      "l'\n",
      "Et\n",
      "pourtant\n",
      "de\n",
      "première\n",
      "l'\n",
      "les\n",
      "humiliant\n",
      "pour\n",
      "à\n",
      "autour\n",
      "du\n",
      "sont\n",
      "à\n",
      "leur\n",
      "ne\n",
      "parce\n",
      "que\n",
      "depuis\n",
      "on\n",
      "n'\n",
      "pas\n",
      "mais\n",
      "est\n",
      "à\n",
      "lui\n",
      "s'\n",
      "en\n",
      "y\n",
      "en\n",
      "a\n",
      "qui\n",
      "en\n",
      "toute\n",
      "et\n",
      "telle\n",
      "ou\n",
      "telle\n",
      "telle\n",
      "ou\n",
      "telle\n",
      "en\n",
      "toute\n",
      "parce\n",
      "leur\n",
      "comme\n",
      "les\n",
      "Waterproof\n",
      "d'\n",
      "une\n",
      "du\n",
      "a\n",
      "Pour\n",
      "que\n",
      "l'\n",
      "essentiel\n",
      "est\n",
      "dans\n",
      "l'\n",
      "du\n",
      "que\n",
      "vous\n",
      "Est\n",
      "fait\n",
      "ou\n",
      "une\n",
      "que\n",
      "toute\n",
      "la\n",
      "entre\n",
      "le\n",
      "et\n",
      "la\n",
      "soit\n",
      "Maintenant\n",
      "avec\n",
      "peu\n",
      "de\n",
      "bonne\n",
      "volonté\n",
      "vous\n",
      "que\n",
      "on\n",
      "être\n",
      "ET\n",
      "mais\n",
      "n'\n",
      "pas\n",
      "et\n",
      "Royale\n",
      "cette\n",
      "de\n",
      "est\n",
      "à\n",
      "être\n",
      "et\n",
      "Pour\n",
      "à\n",
      "bien\n",
      "le\n",
      "de\n",
      "interne\n",
      "pour\n",
      "risques\n",
      "externes\n",
      "par\n",
      "Occidental\n",
      "Belle\n",
      "claire\n",
      "à\n",
      "souhait\n",
      "est\n",
      "Et\n",
      "si\n",
      "officiellement\n",
      "n'\n",
      "ouvertes\n",
      "n'\n",
      "a\n",
      "jamais\n",
      "des\n",
      "de\n",
      "se\n",
      "au\n",
      "plus\n",
      "déchirée\n",
      "cette\n",
      "sera\n",
      "à\n",
      "pour\n",
      "sur\n",
      "de\n",
      "régional\n",
      "des\n",
      "Union\n",
      "sur\n",
      "notamment\n",
      "des\n",
      "Le\n",
      "__DIGIT__\n",
      "le\n",
      "Secrétaire\n",
      "l'\n",
      "Elysée\n",
      "et\n",
      "le\n",
      "Premier\n",
      "ministre\n",
      "qui\n",
      "ces\n",
      "est\n",
      "l'\n",
      "et\n",
      "un\n",
      "peuple\n",
      "et\n",
      "de\n",
      "ses\n",
      "ce\n",
      "la\n",
      "une\n",
      "ou\n",
      "la\n",
      "de\n",
      "Ne\n",
      "ou\n",
      "isolée\n",
      "Autant\n",
      "un\n",
      "sont\n",
      "Pour\n",
      "que\n",
      "premier\n",
      "de\n",
      "ne\n",
      "sous\n",
      "et\n",
      "pour\n",
      "autant\n",
      "ne\n",
      "dans\n",
      "nouvelle\n",
      "N'\n",
      "-pas\n",
      "la\n",
      "faire\n",
      "autour\n",
      "vous\n",
      "naissait\n",
      "iii\n",
      "La\n",
      "foncière\n",
      "est\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "en\n",
      "Car\n",
      "où\n",
      "financière\n",
      "qui\n",
      "de\n",
      "faisait\n",
      "toute\n",
      "cette\n",
      "et\n",
      "bien\n",
      "au-delà\n",
      "s'\n",
      "est\n",
      "mais\n",
      "dans\n",
      "l'\n",
      "si\n",
      "extérieure\n",
      "est\n",
      "en\n",
      "bons\n",
      "intermédiaires\n",
      "pour\n",
      "négocier\n",
      "est\n",
      "la\n",
      "est\n",
      "un\n",
      "dans\n",
      "les\n",
      "qui\n",
      "sa\n",
      "l'\n",
      "agenda\n",
      "sera\n",
      "le\n",
      "Combien\n",
      "de\n",
      "ne\n",
      "-nous\n",
      "que\n",
      "nous-mêmes\n",
      "et\n",
      "ne\n",
      "-nous\n",
      "même\n",
      "pas\n",
      "de\n",
      "Tout\n",
      "est\n",
      "présent\n",
      "Plus\n",
      "l'\n",
      "tente\n",
      "de\n",
      "des\n",
      "autant\n",
      "avec\n",
      "au\n",
      "du\n",
      "la\n",
      "Occidental\n",
      "est\n",
      "La\n",
      "française\n",
      "n'\n",
      "a\n",
      "qu'\n",
      "et\n",
      "se\n",
      "la\n",
      "contre\n",
      "été\n",
      "massive\n",
      "et\n",
      "pas\n",
      "moins\n",
      "et\n",
      "à\n",
      "des\n",
      "du\n",
      "Personne\n",
      "ne\n",
      "aucune\n",
      "politique\n",
      "Mais\n",
      "la\n",
      "que\n",
      "n'\n",
      "est\n",
      "pas\n",
      "ou\n",
      "l'\n",
      "l'\n",
      "que\n",
      "toujours\n",
      "se\n",
      "et\n",
      "n'\n",
      "aucun\n",
      "mal\n",
      "à\n",
      "Y\n",
      "-t\n",
      "un\n",
      "de\n",
      "les\n",
      "mal\n",
      "en\n",
      "est\n",
      "y\n",
      "de\n",
      "tout\n",
      "par\n",
      "sous\n",
      "La\n",
      "Ligue\n",
      "des\n",
      "La\n",
      "Nouvelle\n",
      "les\n",
      "__DIGIT__\n",
      "premiers\n",
      "animée\n",
      "__DIGIT__\n",
      "du\n",
      "dernier\n",
      "par\n",
      "l'\n",
      "s'\n",
      "que\n",
      "de\n",
      "d'\n",
      "eau\n",
      "ne\n",
      "soit\n",
      "si\n",
      "brillant\n",
      "que\n",
      "au\n",
      "Berlinale\n",
      "Territoire\n",
      "perdu\n",
      "s'\n",
      "cette\n",
      "avantgardiste\n",
      "et\n",
      "engagée\n",
      "si\n",
      "cela\n",
      "pour\n",
      "aujourd'hui\n",
      "était\n",
      "petite\n",
      "du\n",
      "ouvert\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "jeunes\n",
      "sahraouis\n",
      "à\n",
      "un\n",
      "à\n",
      "et\n",
      "à\n",
      "se\n",
      "pour\n",
      "dans\n",
      "colonisée\n",
      "et\n",
      "un\n",
      "à\n",
      "toutes\n",
      "contre\n",
      "sahraouie\n",
      "à\n",
      "les\n",
      "Nations\n",
      "à\n",
      "libre\n",
      "et\n",
      "à\n",
      "un\n",
      "par\n",
      "Maroc\n",
      "des\n",
      "du\n",
      "Occidental\n",
      "se\n",
      "comprends\n",
      "bien\n",
      "votre\n",
      "par\n",
      "à\n",
      "ce\n",
      "n'\n",
      "comme\n",
      "aujourd'hui\n",
      "hamed\n",
      "et\n",
      "deux\n",
      "des\n",
      "comme\n",
      "Mme\n",
      "étaient\n",
      "fait\n",
      "dernier\n",
      "à\n",
      "de\n",
      "la\n",
      "du\n",
      "parce\n",
      "ils\n",
      "étaient\n",
      "des\n",
      "qui\n",
      "étaient\n",
      "des\n",
      "sans\n",
      "de\n",
      "A\n",
      "chaque\n",
      "le\n",
      "appelle\n",
      "quelqu'un\n",
      "son\n",
      "et\n",
      "été\n",
      "Qui\n",
      "a\n",
      "La\n",
      "intègre\n",
      "une\n",
      "RSA\n",
      "car\n",
      "de\n",
      "est\n",
      "bien\n",
      "d'\n",
      "sur\n",
      "le\n",
      "au\n",
      "être\n",
      "l'\n",
      "PPE\n",
      "N'\n",
      "étant\n",
      "pour\n",
      "plus\n",
      "dix\n",
      "mille\n",
      "les\n",
      "qui\n",
      "tout\n",
      "ce\n",
      "pour\n",
      "ce\n",
      "ininterrompu\n",
      "craignent\n",
      "ne\n",
      "si\n",
      "l'\n",
      "ne\n",
      "plus\n",
      "vite\n",
      "son\n",
      "nez\n",
      "Ces\n",
      "de\n",
      "différentes\n",
      "Espagnols\n",
      "Britanniques\n",
      "Argentins\n",
      "Cubains\n",
      "Sud-Africains\n",
      "est\n",
      "à\n",
      "où\n",
      "qui\n",
      "de\n",
      "se\n",
      "sont\n",
      "les\n",
      "traiter\n",
      "en\n",
      "tant\n",
      "indigènes\n",
      "en\n",
      "à\n",
      "un\n",
      "de\n",
      "que\n",
      "des\n",
      "Ont\n",
      "à\n",
      "cette\n",
      "des\n",
      "du\n",
      "Algérie\n",
      "d'\n",
      "du\n",
      "de\n",
      "du\n",
      "d'\n",
      "et\n",
      "du\n",
      "Attention\n",
      "même\n",
      "n'\n",
      "est\n",
      "un\n",
      "encore\n",
      "moins\n",
      "un\n",
      "de\n",
      "ce\n",
      "que\n",
      "été\n",
      "Et\n",
      "est\n",
      "la\n",
      "plus\n",
      "du\n",
      "l'\n",
      "des\n",
      "trois\n",
      "opérateurs\n",
      "de\n",
      "l'\n",
      "et\n",
      "est\n",
      "au\n",
      "m'\n",
      "de\n",
      "le\n",
      "pensent\n",
      "n'\n",
      "pas\n",
      "à\n",
      "l'\n",
      "en\n",
      "tant\n",
      "que\n",
      "premier\n",
      "du\n",
      "d'\n",
      "des\n",
      "l'\n",
      "des\n",
      "et\n",
      "des\n",
      "et\n",
      "à\n",
      "des\n",
      "de\n",
      "n'\n",
      "pour\n",
      "une\n",
      "très\n",
      "Dès\n",
      "que\n",
      "décide\n",
      "sa\n",
      "il\n",
      "instantanément\n",
      "et\n",
      "de\n",
      "libre\n",
      "Que\n",
      "l'\n",
      "Eglise\n",
      "sur\n",
      "ce\n",
      "délicat\n",
      "elle\n",
      "elle\n",
      "En\n",
      "l'\n",
      "de\n",
      "ce\n",
      "à\n",
      "du\n",
      "pour\n",
      "mieux\n",
      "du\n",
      "aujourd'hui\n",
      "En\n",
      "de\n",
      "ce\n",
      "les\n",
      "__DIGIT__\n",
      "et\n",
      "du\n",
      "des\n",
      "CGI\n",
      "en\n",
      "de\n",
      "la\n",
      "et\n",
      "l'\n",
      "étranger\n",
      "l'\n",
      "et\n",
      "de\n",
      "aux\n",
      "grands\n",
      "à\n",
      "du\n",
      "aux\n",
      "jeunes\n",
      "avoir\n",
      "l'\n",
      "les\n",
      "deux\n",
      "ont\n",
      "leur\n",
      "d'\n",
      "à\n",
      "leur\n",
      "et\n",
      "à\n",
      "leur\n",
      "C'\n",
      "est\n",
      "de\n",
      "cette\n",
      "que\n",
      "nouvelles\n",
      "été\n",
      "durant\n",
      "les\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "me\n",
      "s'\n",
      "qui\n",
      "des\n",
      "pour\n",
      "des\n",
      "en\n",
      "que\n",
      "le\n",
      "sous\n",
      "au\n",
      "des\n",
      "cette\n",
      "au\n",
      "France\n",
      "l'\n",
      "en\n",
      "son\n",
      "Veto\n",
      "à\n",
      "des\n",
      "pour\n",
      "la\n",
      "et\n",
      "le\n",
      "contrôle\n",
      "des\n",
      "l'\n",
      "une\n",
      "se\n",
      "de\n",
      "ce\n",
      "n'\n",
      "est\n",
      "soi\n",
      "à\n",
      "ce\n",
      "immédiat\n",
      "du\n",
      "beau\n",
      "et\n",
      "du\n",
      "bien\n",
      "qui\n",
      "nous\n",
      "le\n",
      "--\n",
      "son\n",
      "--\n",
      "avant\n",
      "le\n",
      "que\n",
      "étaient\n",
      "tout\n",
      "au\n",
      "un\n",
      "les\n",
      "mais\n",
      "on\n",
      "tous\n",
      "dans\n",
      "n'\n",
      "en\n",
      "ce\n",
      "--\n",
      "maintenant\n",
      "bien\n",
      "--\n",
      "et\n",
      "l'\n",
      "au\n",
      "VI\n",
      "les\n",
      "auraient\n",
      "au\n",
      "Pour\n",
      "le\n",
      "Occidental\n",
      "__DIGIT__\n",
      "et\n",
      "au\n",
      "dans\n",
      "la\n",
      "plus\n",
      "que\n",
      "me\n",
      "a\n",
      "à\n",
      "de\n",
      "l'\n",
      "éprouve\n",
      "selon\n",
      "un\n",
      "au\n",
      "une\n",
      "islamique\n",
      "L'\n",
      "La\n",
      "Camella\n",
      "blanca\n",
      "aux\n",
      "ont\n",
      "que\n",
      "ce\n",
      "a\n",
      "d'\n",
      "l'\n",
      "l'\n",
      "courageux\n",
      "pacifique\n",
      "mais\n",
      "du\n",
      "Tenue\n",
      "mois\n",
      "précédente\n",
      "réunion\n",
      "Malte\n",
      "cette\n",
      "nouvelle\n",
      "se\n",
      "sous\n",
      "l'\n",
      "envoyé\n",
      "du\n",
      "des\n",
      "Nations\n",
      "pour\n",
      "M.\n",
      "en\n",
      "des\n",
      "des\n",
      "deux\n",
      "parties\n",
      "et\n",
      "des\n",
      "des\n",
      "deux\n",
      "observateurs\n",
      "l'\n",
      "et\n",
      "la\n",
      "Le\n",
      "fut\n",
      "la\n",
      "A\n",
      "du\n",
      "ou\n",
      "s'\n",
      "a\n",
      "en\n",
      "et\n",
      "deux\n",
      "Pour\n",
      "l'\n",
      "ou\n",
      "Forum\n",
      "des\n",
      "exportateurs\n",
      "de\n",
      "est\n",
      "en\n",
      "__DIGIT__\n",
      "N'\n",
      "à\n",
      "m'\n",
      "actualités\n",
      "et\n",
      "tribunes\n",
      "à\n",
      "Jusqu'\n",
      "à\n",
      "quand\n",
      "officielle\n",
      "-t\n",
      "sa\n",
      "des\n",
      "l'\n",
      "n'\n",
      "y\n",
      "en\n",
      "a\n",
      "M.\n",
      "-t\n",
      "à\n",
      "faire\n",
      "Rabat\n",
      "du\n",
      "entre\n",
      "d'\n",
      "un\n",
      "permanent\n",
      "du\n",
      "l'\n",
      "la\n",
      "l'\n",
      "l'\n",
      "de\n",
      "un\n",
      "plusieurs\n",
      "une\n",
      "lui\n",
      "La\n",
      "de\n",
      "de\n",
      "déconseille\n",
      "aux\n",
      "de\n",
      "se\n",
      "à\n",
      "__DIGIT__\n",
      "l'\n",
      "de\n",
      "qui\n",
      "une\n",
      "contre\n",
      "__DIGIT__\n",
      "l'\n",
      "passée\n",
      "Moi\n",
      "plus\n",
      "je\n",
      "des\n",
      "ce\n",
      "plus\n",
      "je\n",
      "me\n",
      "que\n",
      "__DIGIT__\n",
      "sera\n",
      "THE\n",
      "GAME\n",
      "pour\n",
      "vrais\n",
      "soldats\n",
      "qui\n",
      "ont\n",
      "La\n",
      "et\n",
      "l'\n",
      "sera\n",
      "Eurosites\n",
      "en\n",
      "France\n",
      "Maintenant\n",
      "si\n",
      "des\n",
      "au\n",
      "une\n",
      "pour\n",
      "faire\n",
      "à\n",
      "qu'\n",
      "nous\n",
      "le\n",
      "fassent\n",
      "savoir\n",
      "Elle\n",
      "se\n",
      "et\n",
      "un\n",
      "autre\n",
      "naître\n",
      "Outre\n",
      "ses\n",
      "et\n",
      "la\n",
      "jeunes\n",
      "personnages\n",
      "l'\n",
      "sont\n",
      "kemonomimi\n",
      "soit\n",
      "avec\n",
      "des\n",
      "oreilles\n",
      "et\n",
      "des\n",
      "Ces\n",
      "jeune\n",
      "âge\n",
      "mais\n",
      "l'\n",
      "et\n",
      "la\n",
      "de\n",
      "leurs\n",
      "ils\n",
      "en\n",
      "que\n",
      "si\n",
      "qui\n",
      "n'\n",
      "avaient\n",
      "pas\n",
      "__DIGIT__\n",
      "mg/100\n",
      "ml\n",
      "1er\n",
      "janvier\n",
      "une\n",
      "telle\n",
      "__DIGIT__\n",
      "été\n",
      "__DIGIT__\n",
      "le\n",
      "Mia\n",
      "Du\n",
      "dont\n",
      "le\n",
      "privée\n",
      "du\n",
      "ne\n",
      "Le\n",
      "bien\n",
      "que\n",
      "feutré\n",
      "est\n",
      "vous\n",
      "avons\n",
      "accueilli\n",
      "est\n",
      "de\n",
      "nous\n",
      "nos\n",
      "Après-midi\n",
      "libre\n",
      "de\n",
      "commentées\n",
      "au\n",
      "de\n",
      "les\n",
      "avec\n",
      "lui\n",
      "l'\n",
      "Eclipse\n",
      "pour\n",
      "contre\n",
      "de\n",
      "__DIGIT__\n",
      "est\n",
      "ne\n",
      "tant\n",
      "que\n",
      "n'\n",
      "été\n",
      "a\n",
      "d'\n",
      "eux\n",
      "Après\n",
      "M.\n",
      "chez\n",
      "depuis\n",
      "est\n",
      "M.\n",
      "a\n",
      "matin\n",
      "son\n",
      "et\n",
      "ses\n",
      "son\n",
      "Un\n",
      "été\n",
      "pour\n",
      "anniversaire\n",
      "écrivain\n",
      "et\n",
      "du\n",
      "le\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "à\n",
      "Au\n",
      "cette\n",
      "et\n",
      "son\n",
      "à\n",
      "pour\n",
      "au\n",
      "et\n",
      "de\n",
      "L'\n",
      "d'\n",
      "en\n",
      "est\n",
      "favori\n",
      "contre\n",
      "__DIGIT__\n",
      "et\n",
      "son\n",
      "plus\n",
      "limité\n",
      "chez\n",
      "en\n",
      "aller\n",
      "des\n",
      "de\n",
      "Ligue\n",
      "mais\n",
      "quelques\n",
      "au\n",
      "comme\n",
      "à\n",
      "l'\n",
      "Quatre\n",
      "plus\n",
      "pourront\n",
      "se\n",
      "de\n",
      "ce\n",
      "au\n",
      "à\n",
      "de\n",
      "appels\n",
      "Charles\n",
      "avant\n",
      "répondre\n",
      "aux\n",
      "soulevées\n",
      "que\n",
      "y\n",
      "été\n",
      "soir\n",
      "est\n",
      "à\n",
      "TriBeCa\n",
      "un\n",
      "du\n",
      "Depuis\n",
      "l'\n",
      "la\n",
      "à\n",
      "en\n",
      "ses\n",
      "de\n",
      "première\n",
      "louvoie\n",
      "pourtant\n",
      "soutien\n",
      "et\n",
      "prise\n",
      "de\n",
      "comment\n",
      "n'\n",
      "est\n",
      "seulement\n",
      "la\n",
      "plus\n",
      "disputée\n",
      "l'\n",
      "est\n",
      "la\n",
      "plus\n",
      "avec\n",
      "+\n",
      "Facebookant\n",
      "et\n",
      "Tweetant\n",
      "+\n",
      "en\n",
      "participant\n",
      "record\n",
      "aux\n",
      "samedi\n",
      "Straits\n",
      "Times\n",
      "du\n",
      "comme\n",
      "Odeurs\n",
      "tout\n",
      "se\n",
      "pour\n",
      "plus\n",
      "des\n",
      "et\n",
      "de\n",
      "dernière\n",
      "génération\n",
      "la\n",
      "supérieure\n",
      "la\n",
      "à\n",
      "C\n",
      "et\n",
      "que\n",
      "couches\n",
      "plus\n",
      "__DIGIT__\n",
      "C\n",
      "est\n",
      "de\n",
      "un\n",
      "peu\n",
      "de\n",
      "qui\n",
      "se\n",
      "fait\n",
      "l'\n",
      "de\n",
      "faisant\n",
      "croire\n",
      "aux\n",
      "l'\n",
      "!\n",
      "De\n",
      "à\n",
      "une\n",
      "certaine\n",
      "L'\n",
      "brut\n",
      "d'\n",
      "d'\n",
      "en\n",
      "et\n",
      "le\n",
      "courant\n",
      "une\n",
      "à\n",
      "Pour\n",
      "autant\n",
      "par\n",
      "est\n",
      "meilleure\n",
      "parmi\n",
      "ayant\n",
      "moins\n",
      "cette\n",
      "a\n",
      "la\n",
      "L'\n",
      "du\n",
      "demande\n",
      "et\n",
      "surtout\n",
      "que\n",
      "soit\n",
      "la\n",
      "s'\n",
      "est\n",
      "2:00.531\n",
      "comme\n",
      "et\n",
      "Jorge\n",
      "tous\n",
      "deux\n",
      "sur\n",
      "et\n",
      "distancés\n",
      "de\n",
      "moins\n",
      "de\n",
      "de\n",
      "du\n",
      "cas\n",
      "la\n",
      "des\n",
      "IP\n",
      "ne\n",
      "bonne\n",
      "pour\n",
      "qui\n",
      "de\n",
      "plus\n",
      "plus\n",
      "pied\n",
      "au\n",
      "tout\n",
      "au\n",
      "le\n",
      "peuple\n",
      "notre\n",
      "que\n",
      "leur\n",
      "ne\n",
      "de\n",
      "plus\n",
      "un\n",
      "la\n",
      "n'\n",
      "est\n",
      "pas\n",
      "même\n",
      "Société\n",
      "dont\n",
      "la\n",
      "pourrait\n",
      "deux\n",
      "d'\n",
      "qui\n",
      "auparavant\n",
      "voyaient\n",
      "d'\n",
      "un\n",
      "mauvais\n",
      "l'\n",
      "de\n",
      "reconnaissent\n",
      "maintenant\n",
      "de\n",
      "Ca\n",
      "beaucoup\n",
      "de\n",
      "mais\n",
      "pour\n",
      "l'\n",
      "est\n",
      "__DIGIT__\n",
      "%\n",
      "des\n",
      "est\n",
      "un\n",
      "ces\n",
      "de\n",
      "par\n",
      "leur\n",
      "et\n",
      "leur\n",
      "ont\n",
      "la\n",
      "des\n",
      "la\n",
      "s'\n",
      "des\n",
      "par\n",
      "Comité\n",
      "pour\n",
      "du\n",
      "On\n",
      "s'\n",
      "était\n",
      "Quand\n",
      "on\n",
      "un\n",
      "premier\n",
      "de\n",
      "on\n",
      "s'\n",
      "un\n",
      "peu\n",
      "plus\n",
      "toutefois\n",
      "est\n",
      "bon\n",
      "pour\n",
      "tout\n",
      "jouissant\n",
      "une\n",
      "de\n",
      "une\n",
      "ou\n",
      "plusieurs\n",
      "Qu'\n",
      "est\n",
      "-ce\n",
      "que\n",
      "quand\n",
      "on\n",
      "en\n",
      "et\n",
      "qu'\n",
      "on\n",
      "en\n",
      "tous\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "h\n",
      "et\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "a\n",
      "-t\n",
      "-il\n",
      "ce\n",
      "en\n",
      "avoir\n",
      "du\n",
      "au\n",
      "Ce\n",
      "__DIGIT__\n",
      "à\n",
      "sur\n",
      "Là\n",
      "on\n",
      "saura\n",
      "qui\n",
      "est\n",
      "coupable\n",
      "et\n",
      "est\n",
      "a\n",
      "la\n",
      "vous\n",
      "Le\n",
      "Football\n",
      "Atlantique\n",
      "Rochelais\n",
      "un\n",
      "moins\n",
      "des\n",
      "sera\n",
      "l'\n",
      "ultime\n",
      "de\n",
      "pour\n",
      "la\n",
      "des\n",
      "chez\n",
      "de\n",
      "plus\n",
      "plus\n",
      "et\n",
      "quelques\n",
      "plus\n",
      "l'\n",
      "incontournable\n",
      "épreuve\n",
      "qui\n",
      "cette\n",
      "se\n",
      "open\n",
      "Lourdement\n",
      "milliards\n",
      "d'\n",
      "fin\n",
      "__DIGIT__\n",
      "a\n",
      "l'\n",
      "__DIGIT__\n",
      "en\n",
      "du\n",
      "PIB\n",
      "et\n",
      "un\n",
      "à\n",
      "plus\n",
      "Certes\n",
      "la\n",
      "se\n",
      "des\n",
      "Europe\n",
      "sur\n",
      "du\n",
      "La\n",
      "deuxième\n",
      "du\n",
      "Monde\n",
      "son\n",
      "premier\n",
      "__DIGIT__\n",
      "en\n",
      "XV\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "dimanche\n",
      "à\n",
      "Park\n",
      "a\n",
      "de\n",
      "faire\n",
      "un\n",
      "pour\n",
      "se\n",
      "l'\n",
      "de\n",
      "japonaise\n",
      "n'\n",
      "a\n",
      "l'\n",
      "au\n",
      "__DIGIT__\n",
      "Comme\n",
      "chaque\n",
      "soir\n",
      "à\n",
      "il\n",
      "malmène\n",
      "et\n",
      "l'\n",
      "Côté\n",
      "la\n",
      "va\n",
      "son\n",
      "logistique\n",
      "au\n",
      "__DIGIT__\n",
      "et\n",
      "à\n",
      "du\n",
      "l'\n",
      "reste\n",
      "un\n",
      "Faut\n",
      "-il\n",
      "de\n",
      "se\n",
      "du\n",
      "a\n",
      "du\n",
      "l'\n",
      "pour\n",
      "se\n",
      "__DIGIT__\n",
      "au\n",
      "mon\n",
      "déplacement\n",
      "à\n",
      "que\n",
      "étaient\n",
      "probablement\n",
      "plus\n",
      "Fini\n",
      "jeune\n",
      "Haupais\n",
      "qui\n",
      "sa\n",
      "CM1\n",
      "Plus\n",
      "ont\n",
      "en\n",
      "outre\n",
      "été\n",
      "dont\n",
      "une\n",
      "grièvement\n",
      "lors\n",
      "d'\n",
      "dans\n",
      "des\n",
      "selon\n",
      "ces\n",
      "à\n",
      "l'\n",
      "deux\n",
      "autres\n",
      "délégués\n",
      "pour\n",
      "aux\n",
      "mais\n",
      "parents\n",
      "Sur\n",
      "place\n",
      "vente\n",
      "de\n",
      "à\n",
      "tout\n",
      "ce\n",
      "une\n",
      "de\n",
      "qui\n",
      "été\n",
      "Le\n",
      "a\n",
      "d'\n",
      "ailleurs\n",
      "été\n",
      "hier\n",
      "par\n",
      "général\n",
      "au\n",
      "parlementaire\n",
      "du\n",
      "Changement\n",
      "et\n",
      "de\n",
      "a\n",
      "que\n",
      "nul\n",
      "n'\n",
      "a\n",
      "de\n",
      "De\n",
      "plus\n",
      "une\n",
      "Salon\n",
      "du\n",
      "deux\n",
      "__DIGIT__\n",
      "et\n",
      "à\n",
      "Loire\n",
      "Ça\n",
      "me\n",
      "des\n",
      "à\n",
      "une\n",
      "intégrée\n",
      "aux\n",
      "reconnues\n",
      "et\n",
      "la\n",
      "sortant\n",
      "les\n",
      "rapidement\n",
      "leur\n",
      "et\n",
      "leur\n",
      "sur\n",
      "Chaque\n",
      "des\n",
      "de\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "en\n",
      "sur\n",
      "dont\n",
      "le\n",
      "avait\n",
      "de\n",
      "francophone\n",
      "a\n",
      "lundi\n",
      "que\n",
      "l'\n",
      "emporter\n",
      "des\n",
      "bien\n",
      "mais\n",
      "se\n",
      "aux\n",
      "l'\n",
      "Europe\n",
      "et\n",
      "moins\n",
      "est\n",
      "sur\n",
      "et\n",
      "la\n",
      "souverain\n",
      "explique\n",
      "chez\n",
      "Quel\n",
      "est\n",
      "un\n",
      "tel\n",
      "qui\n",
      "l'\n",
      "de\n",
      "nouvelles\n",
      "ou\n",
      "l'\n",
      "a\n",
      "fait\n",
      "__DIGIT__\n",
      "UA\n",
      "UA\n",
      "Pour\n",
      "du\n",
      "Théâtre\n",
      "la\n",
      "a\n",
      "de\n",
      "faire\n",
      "les\n",
      "et\n",
      "le\n",
      "Mardi\n",
      "l'\n",
      "était\n",
      "en\n",
      "En\n",
      "la\n",
      "été\n",
      "peu\n",
      "moins\n",
      "que\n",
      "pires\n",
      "saisons\n",
      "Cependant\n",
      "à\n",
      "certain\n",
      "être\n",
      "la\n",
      "jeune\n",
      "a\n",
      "un\n",
      "en\n",
      "pour\n",
      "sa\n",
      "est\n",
      "une\n",
      "bonne\n",
      "pour\n",
      "deux\n",
      "sur\n",
      "sourit\n",
      "hier\n",
      "matin\n",
      "--\n",
      "de\n",
      "L'\n",
      "--\n",
      "comme\n",
      "un\n",
      "qui\n",
      "à\n",
      "au\n",
      "l'\n",
      "dans\n",
      "premier\n",
      "bien\n",
      "de\n",
      "mais\n",
      "c'\n",
      "est\n",
      "sans\n",
      "DARGAUD\n",
      "vos\n",
      "coordonnées\n",
      "au\n",
      "d'\n",
      "du\n",
      "SMS\n",
      "et\n",
      "au\n",
      "quiz\n",
      "est\n",
      "de\n",
      "que\n",
      "et\n",
      "essayant\n",
      "de\n",
      "l'\n",
      "serait\n",
      "plus\n",
      "libérateur\n",
      "crier\n",
      "bien\n",
      "fort\n",
      "OUACHE\n",
      "Une\n",
      "d'\n",
      "et\n",
      "le\n",
      "contrôle\n",
      "des\n",
      "au\n",
      "malgré\n",
      "la\n",
      "de\n",
      "faire\n",
      "croître\n",
      "son\n",
      "net\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "d'\n",
      "malgré\n",
      "__DIGIT__\n",
      "de\n",
      "pour\n",
      "été\n",
      "et\n",
      "ce\n",
      "la\n",
      "premier\n",
      "la\n",
      "n'\n",
      "et\n",
      "la\n",
      "ne\n",
      "ce\n",
      "que\n",
      "est\n",
      "n'\n",
      "a\n",
      "de\n",
      "répéter\n",
      "cet\n",
      "par\n",
      "au\n",
      "dont\n",
      "la\n",
      "à\n",
      "n'\n",
      "a\n",
      "à\n",
      "rien\n",
      "Et\n",
      "n'\n",
      "est\n",
      "à\n",
      "essai\n",
      "Hormis\n",
      "ce\n",
      "au\n",
      "qui\n",
      "quand\n",
      "elle\n",
      "le\n",
      "voyait\n",
      "sourire\n",
      "se\n",
      "elle\n",
      "Pendant\n",
      "que\n",
      "Etat\n",
      "Major\n",
      "des\n",
      "incontrôlés\n",
      "des\n",
      "Garde\n",
      "le\n",
      "Huit\n",
      "militaires\n",
      "jusqu'\n",
      "aux\n",
      "un\n",
      "de\n",
      "à\n",
      "à\n",
      "quelques\n",
      "Oui\n",
      "on\n",
      "le\n",
      "mais\n",
      "je\n",
      "la\n",
      "faut\n",
      "La\n",
      "des\n",
      "se\n",
      "cette\n",
      "à\n",
      "-\n",
      "Le\n",
      "un\n",
      "niveau\n",
      "plus\n",
      "que\n",
      "ne\n",
      "que\n",
      "tout\n",
      "pour\n",
      "plus\n",
      "A\n",
      "__DIGIT__\n",
      "à\n",
      "du\n",
      "Accueil\n",
      "de\n",
      "qui\n",
      "de\n",
      "et\n",
      "des\n",
      "à\n",
      "hispanique\n",
      "de\n",
      "le\n",
      "et\n",
      "à\n",
      "très\n",
      "Allez-y\n",
      "je\n",
      "retournes\n",
      "au\n",
      "son\n",
      "là\n",
      "pour\n",
      "à\n",
      "votre\n",
      "la\n",
      "est\n",
      "et\n",
      "un\n",
      "bon\n",
      "et\n",
      "y\n",
      "est\n",
      "une\n",
      "dont\n",
      "les\n",
      "et\n",
      "photovoltaïque\n",
      "ne\n",
      "quelques\n",
      "bien\n",
      "et\n",
      "n'\n",
      "plus\n",
      "mal\n",
      "à\n",
      "anciennement\n",
      "menu\n",
      "en\n",
      "du\n",
      "pas\n",
      "avec\n",
      "beaucoup\n",
      "de\n",
      "autour\n",
      "et\n",
      "une\n",
      "une\n",
      "une\n",
      "après\n",
      "on\n",
      "la\n",
      "les\n",
      "pour\n",
      "faire\n",
      "était\n",
      "de\n",
      "l'\n",
      "Avec\n",
      "plus\n",
      "est\n",
      "une\n",
      "dans\n",
      "la\n",
      "Bon\n",
      "pour\n",
      "être\n",
      "et\n",
      "Bonjour\n",
      "un\n",
      "modèle\n",
      "__DIGIT__\n",
      "Boutique\n",
      "mais\n",
      "il\n",
      "l'\n",
      "Bref\n",
      "la\n",
      "des\n",
      "de\n",
      "nancy\n",
      "vous\n",
      "de\n",
      "trouver\n",
      "bien\n",
      "mieux\n",
      "Bref\n",
      "à\n",
      "!\n",
      "Bémol\n",
      "des\n",
      "est\n",
      "de\n",
      "de\n",
      "de\n",
      "est\n",
      "rare\n",
      "de\n",
      "pouvoir\n",
      "au\n",
      "est\n",
      "un\n",
      "car\n",
      "il\n",
      "de\n",
      "une\n",
      "qui\n",
      "la\n",
      "Cà\n",
      "oui\n",
      "on\n",
      "que\n",
      "était\n",
      "et\n",
      "comme\n",
      "Car\n",
      "l'\n",
      "on\n",
      "aisément\n",
      "des\n",
      "usagés\n",
      "sur\n",
      "les\n",
      "que\n",
      "je\n",
      "du\n",
      "et\n",
      "est\n",
      "1ère\n",
      "fois\n",
      "que\n",
      "je\n",
      "sur\n",
      "Cette\n",
      "est\n",
      "bien\n",
      "et\n",
      "aide\n",
      "beaucoup\n",
      "à\n",
      "toucher\n",
      "débattre\n",
      "à\n",
      "Emplacement\n",
      "pour\n",
      "qui\n",
      "quelqu'un\n",
      "!\n",
      "__DIGIT__\n",
      "et\n",
      "aisselles\n",
      "déjà\n",
      "la\n",
      "que\n",
      "de\n",
      "et\n",
      "aux\n",
      "autres\n",
      "qui\n",
      "à\n",
      "de\n",
      "cette\n",
      "En\n",
      "plus\n",
      "il\n",
      "est\n",
      "à\n",
      "l'\n",
      "et\n",
      "on\n",
      "les\n",
      "la\n",
      "qui\n",
      "est\n",
      "servies\n",
      "un\n",
      "à\n",
      "où\n",
      "l'\n",
      "on\n",
      "du\n",
      "mezcal\n",
      "et\n",
      "des\n",
      "qui\n",
      "ne\n",
      "hors\n",
      "la\n",
      "est\n",
      "trés\n",
      "trés\n",
      "bonne\n",
      "Et\n",
      "un\n",
      "Fini\n",
      "Génial\n",
      "et\n",
      "en\n",
      "plus\n",
      "c'\n",
      "est\n",
      "Ici\n",
      "est\n",
      "sont\n",
      "à\n",
      "vous\n",
      "mieux\n",
      "ce\n",
      "est\n",
      "bien\n",
      "connu\n",
      "et\n",
      "l'\n",
      "à\n",
      "leur\n",
      "ont\n",
      "que\n",
      "est\n",
      "un\n",
      "de\n",
      "quand\n",
      "au\n",
      "N'\n",
      "quoi\n",
      "contre\n",
      "excellent\n",
      "pour\n",
      "'\n",
      "'\n",
      "ont\n",
      "un\n",
      "excellent\n",
      "sur\n",
      "__DIGIT__\n",
      "y\n",
      "car\n",
      "on\n",
      "on\n",
      "qui\n",
      "la\n",
      "et\n",
      "le\n",
      "de\n",
      "ne\n",
      "une\n",
      "+\n",
      "une\n",
      "à\n",
      "par\n",
      "par\n",
      "en\n",
      "cherchant\n",
      "sur\n",
      "un\n",
      "à\n",
      "bien\n",
      "y\n",
      "suis\n",
      "__DIGIT__\n",
      "à\n",
      "et\n",
      "n'\n",
      "été\n",
      "vivement\n",
      "ce\n",
      "à\n",
      "ceux\n",
      "qui\n",
      "de\n",
      "réelles\n",
      "suis\n",
      "élève\n",
      "de\n",
      "et\n",
      "dès\n",
      "elle\n",
      "a\n",
      "d'\n",
      "un\n",
      "au\n",
      "et\n",
      "aux\n",
      "ayurvéda\n",
      "l'\n",
      "veux\n",
      "bien\n",
      "que\n",
      "soit\n",
      "une\n",
      "euro\n",
      "la\n",
      "tout\n",
      "même\n",
      "mais\n",
      "je\n",
      "que\n",
      "ne\n",
      "être\n",
      "l'\n",
      "n'\n",
      "avait\n",
      "même\n",
      "pas\n",
      "été\n",
      "la\n",
      "La\n",
      "regorge\n",
      "tant\n",
      "en\n",
      "La\n",
      "les\n",
      "et\n",
      "les\n",
      "petites\n",
      "être\n",
      "d'\n",
      "environs\n",
      "2cm\n",
      "de\n",
      "plus\n",
      "ce\n",
      "ne\n",
      "__DIGIT__\n",
      "plus\n",
      "ailleurs\n",
      "La\n",
      "Marie-Reine-des-Coeurs\n",
      "est\n",
      "H1M\n",
      "1N4\n",
      "Le\n",
      "est\n",
      "mais\n",
      "l'\n",
      "n'\n",
      "est\n",
      "pas\n",
      "à\n",
      "celle\n",
      "un\n",
      "par\n",
      "de\n",
      "adaptée\n",
      "Le\n",
      "semble\n",
      "à\n",
      "de\n",
      "ne\n",
      "négliger\n",
      "au\n",
      "Le\n",
      "qui\n",
      "ne\n",
      "ce\n",
      "les\n",
      "à\n",
      "n'\n",
      "étaient\n",
      "que\n",
      "et\n",
      "la\n",
      "était\n",
      "savent\n",
      "de\n",
      "et\n",
      "prennent\n",
      "leurs\n",
      "des\n",
      "et\n",
      "le\n",
      "sont\n",
      "plus\n",
      "élevés\n",
      "que\n",
      "dans\n",
      "boutiques\n",
      "mais\n",
      "est\n",
      "le\n",
      "de\n",
      "à\n",
      "!\n",
      "Leur\n",
      "chaud\n",
      "est\n",
      "Madame\n",
      "est\n",
      "une\n",
      "excellente\n",
      "comptable\n",
      "que\n",
      "je\n",
      "Magasin\n",
      "de\n",
      "pour\n",
      "enfants\n",
      "très\n",
      "Mais\n",
      "à\n",
      "que\n",
      "jamais\n",
      "la\n",
      "ne\n",
      "sur\n",
      "nos\n",
      "Merci\n",
      "beaucoup\n",
      "à\n",
      "lui\n",
      "!\n",
      "Nos\n",
      "étaient\n",
      "globalement\n",
      "saumon\n",
      "tagliatelles\n",
      "et\n",
      "de\n",
      "mais\n",
      "restaient\n",
      "et\n",
      "le\n",
      "Notre\n",
      "du\n",
      "vous\n",
      "vos\n",
      "en\n",
      "préservant\n",
      "votre\n",
      "et\n",
      "votre\n",
      "réseau\n",
      "avons\n",
      "pour\n",
      "une\n",
      "un\n",
      "et\n",
      "un\n",
      "__DIGIT__\n",
      "cabines\n",
      "en\n",
      "et\n",
      "saleté\n",
      "au\n",
      "rendez-vous\n",
      "!\n",
      "On\n",
      "y\n",
      "cet\n",
      "Par\n",
      "contre\n",
      "si\n",
      "vous\n",
      "êtes\n",
      "votre\n",
      "est\n",
      "Par\n",
      "contre\n",
      "l'\n",
      "est\n",
      "et\n",
      "la\n",
      "et\n",
      "le\n",
      "Petits\n",
      "de\n",
      "à\n",
      "boire\n",
      "au\n",
      "pour\n",
      "du\n",
      "un\n",
      "succulent\n",
      "qui\n",
      "se\n",
      "Pour\n",
      "ne\n",
      "sont\n",
      "compétent\n",
      "je\n",
      "même\n",
      "totalement\n",
      "première\n",
      "une\n",
      "et\n",
      "été\n",
      "que\n",
      "ami\n",
      "ravi\n",
      "trouver\n",
      "seule\n",
      "et\n",
      "des\n",
      "plus\n",
      "ou\n",
      "de\n",
      "petits\n",
      "moins\n",
      "mais\n",
      "fashion\n",
      "et\n",
      "pour\n",
      "ami\n",
      "un\n",
      "peu\n",
      "plus\n",
      "Pour\n",
      "ils\n",
      "mais\n",
      "il\n",
      "ne\n",
      "jamais\n",
      "Produits\n",
      "super\n",
      "et\n",
      "qui\n",
      "bien\n",
      "sur\n",
      "mon\n",
      "Ps\n",
      "l'\n",
      "on\n",
      "y\n",
      "d'\n",
      "on\n",
      "se\n",
      "le\n",
      "dise\n",
      "Que\n",
      "de\n",
      "plus\n",
      "lorsqu'\n",
      "a\n",
      "et\n",
      "bien\n",
      "décorée\n",
      "Que\n",
      "ce\n",
      "soit\n",
      "à\n",
      "pour\n",
      "ou\n",
      "à\n",
      "pour\n",
      "chez\n",
      "Vallée\n",
      "Toulouse\n",
      "y\n",
      "lorsque\n",
      "absents\n",
      "vous\n",
      "droit\n",
      "au\n",
      "vous\n",
      "vos\n",
      "n'\n",
      "!\n",
      "Son\n",
      "est\n",
      "et\n",
      "à\n",
      "ses\n",
      "d'\n",
      "attente\n",
      "un\n",
      "peu\n",
      "mais\n",
      "nouveaux\n",
      "s'\n",
      "Trop\n",
      "cher\n",
      "meilleure\n",
      "et\n",
      "moins\n",
      "cher\n",
      "propre\n",
      "et\n",
      "bien\n",
      "entretenu\n",
      "une\n",
      "un\n",
      "pour\n",
      "des\n",
      "Voila\n",
      "que\n",
      "ce\n",
      "un\n",
      "peu\n",
      "que\n",
      "est\n",
      "un\n",
      "on\n",
      "on\n",
      "mais\n",
      "un\n",
      "on\n",
      "dans\n",
      "un\n",
      "serait\n",
      "de\n",
      "faire\n",
      "mes\n",
      "serrures\n",
      "à\n",
      "et\n",
      "et\n",
      "Actif\n",
      "a\n",
      "dans\n",
      "deux\n",
      "cas\n",
      "été\n",
      "la\n",
      "ne\n",
      "rien\n",
      "oublier\n",
      "cette\n",
      "au\n",
      "plus\n",
      "__DIGIT__\n",
      "menus\n",
      "à\n",
      "pas\n",
      "deux\n",
      "une\n",
      "pour\n",
      "aux\n",
      "l'\n",
      "électrique\n",
      "à\n",
      "eux\n",
      "car\n",
      "semblaient\n",
      "et\n",
      "bon\n",
      "un\n",
      "Ça\n",
      "une\n",
      "a\n",
      "une\n",
      "du\n",
      "Tour\n",
      "__DIGIT__\n",
      "une\n",
      "du\n",
      "Tour\n",
      "__DIGIT__\n",
      "et\n",
      "de\n",
      "la\n",
      "année\n",
      "autres\n",
      "principaux\n",
      "ce\n",
      "sont\n",
      "et\n",
      "est\n",
      "un\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "à\n",
      "le\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "à\n",
      "Connecticut\n",
      "un\n",
      "à\n",
      "des\n",
      "explique\n",
      "cette\n",
      "est\n",
      "bien\n",
      "sûr\n",
      "des\n",
      "mais\n",
      "du\n",
      "et\n",
      "de\n",
      "l'\n",
      "RADSL\n",
      "-\n",
      "Digital\n",
      "Subscriber\n",
      "Line\n",
      "soit\n",
      "en\n",
      "abonné\n",
      "à\n",
      "cette\n",
      "même\n",
      "perspective\n",
      "et\n",
      "pour\n",
      "les\n",
      "la\n",
      "échangés\n",
      "sont\n",
      "du\n",
      "de\n",
      "l'\n",
      "de\n",
      "l'\n",
      "des\n",
      "du\n",
      "vin\n",
      "et\n",
      "de\n",
      "Cet\n",
      "pour\n",
      "une\n",
      "à\n",
      "soit\n",
      "comme\n",
      "fut\n",
      "nécessaire\n",
      "jusqu'\n",
      "à\n",
      "l'\n",
      "Le\n",
      "__DIGIT__\n",
      "un\n",
      "à\n",
      "est\n",
      "un\n",
      "grand\n",
      "__DIGIT__\n",
      "--\n",
      "est\n",
      "politique\n",
      "République\n",
      "fut\n",
      "l'\n",
      "hauts\n",
      "dirigeants\n",
      "du\n",
      "Parti\n",
      "avant\n",
      "de\n",
      "la\n",
      "et\n",
      "fut\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "fut\n",
      "à\n",
      "par\n",
      "IV\n",
      "et\n",
      "de\n",
      "V\n",
      "de\n",
      "que\n",
      "par\n",
      "certain\n",
      "de\n",
      "étrangers\n",
      "Un\n",
      "de\n",
      "zéro\n",
      "n'\n",
      "pas\n",
      "et\n",
      "ou\n",
      "de\n",
      "d'\n",
      "ou\n",
      "la\n",
      "plus\n",
      "des\n",
      "On\n",
      "décide\n",
      "d'\n",
      "comme\n",
      "le\n",
      "qui\n",
      "est\n",
      "devenu\n",
      "La\n",
      "été\n",
      "le\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "et\n",
      "été\n",
      "au\n",
      "__DIGIT__\n",
      "afin\n",
      "son\n",
      "été\n",
      "s'\n",
      "donc\n",
      "un\n",
      "proche\n",
      "de\n",
      "l'\n",
      "aux\n",
      "et\n",
      "ankylosauriens\n",
      "La\n",
      "Wallace\n",
      "qui\n",
      "et\n",
      "et\n",
      "entre\n",
      "et\n",
      "sépare\n",
      "ces\n",
      "deux\n",
      "sans\n",
      "est\n",
      "et\n",
      "a\n",
      "est\n",
      "ce\n",
      "que\n",
      "as\n",
      "siècles\n",
      "se\n",
      "ensuite\n",
      "vers\n",
      "des\n",
      "plus\n",
      "et\n",
      "Remparts\n",
      "de\n",
      "majeur\n",
      "L'\n",
      "des\n",
      "de\n",
      "et\n",
      "de\n",
      "d'\n",
      "et\n",
      "d'\n",
      "l'\n",
      "est\n",
      "libre\n",
      "Mgr\n",
      "insiste\n",
      "sur\n",
      "deux\n",
      "et\n",
      "la\n",
      "On\n",
      "à\n",
      "__DIGIT__\n",
      "Vallée\n",
      "du\n",
      "est\n",
      "le\n",
      "Premier\n",
      "ministre\n",
      "au\n",
      "sa\n",
      "et\n",
      "que\n",
      "de\n",
      "la\n",
      "de\n",
      "leur\n",
      "en\n",
      "sera\n",
      "et\n",
      "par\n",
      "l'\n",
      "de\n",
      "celle-ci\n",
      "Le\n",
      "du\n",
      "sa\n",
      "le\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "à\n",
      "est\n",
      "sud-africain\n",
      "est\n",
      "premier\n",
      "du\n",
      "album\n",
      "de\n",
      "du\n",
      "Idem\n",
      "pour\n",
      "l'\n",
      "Est\n",
      "-\n",
      "Ouest\n",
      "qui\n",
      "celle\n",
      "la\n",
      "du\n",
      "un\n",
      "de\n",
      "bin\n",
      "parvient\n",
      "en\n",
      "le\n",
      "Pour\n",
      "il\n",
      "en\n",
      "exactement\n",
      "__DIGIT__\n",
      "est\n",
      "d'\n",
      "par\n",
      "également\n",
      "des\n",
      "des\n",
      "et\n",
      "photos\n",
      "de\n",
      "vos\n",
      "La\n",
      "trois\n",
      "points\n",
      "pour\n",
      "de\n",
      "l'\n",
      "kleśa\n",
      "La\n",
      "est\n",
      "retirée\n",
      "l'\n",
      "le\n",
      "Japonais\n",
      "marque\n",
      "du\n",
      "sur\n",
      "des\n",
      "__DIGIT__\n",
      "mètres\n",
      "à\n",
      "des\n",
      "Lafayette\n",
      "dans\n",
      "Revue\n",
      "et\n",
      "Revue\n",
      "février\n",
      "Grenoble\n",
      "sont\n",
      "aux\n",
      "trois\n",
      "de\n",
      "et\n",
      "les\n",
      "un\n",
      "peu\n",
      "des\n",
      "grès\n",
      "roussard\n",
      "matériau\n",
      "une\n",
      "sombre\n",
      "qui\n",
      "à\n",
      "__DIGIT__\n",
      "l'\n",
      "fut\n",
      "son\n",
      "à\n",
      "l'\n",
      "Rebais\n",
      "ou\n",
      "saint\n",
      "Aile\n",
      "été\n",
      "premier\n",
      "Rebais\n",
      "au\n",
      "Le\n",
      "du\n",
      "la\n",
      "une\n",
      "commune\n",
      "aujourd'hui\n",
      "des\n",
      "entre\n",
      "autres\n",
      "des\n",
      "et\n",
      "au\n",
      "future\n",
      "Banque\n",
      "bien\n",
      "réponde\n",
      "aux\n",
      "GPL\n",
      "en\n",
      "le\n",
      "source\n",
      "aucune\n",
      "ce\n",
      "ne\n",
      "sur\n",
      "il\n",
      "fut\n",
      "et\n",
      "appela\n",
      "désormais\n",
      "von\n",
      "le\n",
      "qui\n",
      "sur\n",
      "accuse\n",
      "de\n",
      "n'\n",
      "est\n",
      "que\n",
      "par\n",
      "RD\n",
      "__DIGIT__\n",
      "et\n",
      "RD\n",
      "a\n",
      "en\n",
      "Tiếng\n",
      "địch\n",
      "sông\n",
      "Le\n",
      "une\n",
      "Rivière\n",
      "une\n",
      "qui\n",
      "est\n",
      "deux\n",
      "première\n",
      "deux\n",
      "__DIGIT__\n",
      "et\n",
      "__DIGIT__\n",
      "au\n",
      "Théâtre\n",
      "de\n",
      "et\n",
      "les\n",
      "deux\n",
      "soirées\n",
      "__DIGIT__\n",
      "et\n",
      "__DIGIT__\n",
      "au\n",
      "Théâtre\n",
      "de\n",
      "La\n",
      "première\n",
      "ce\n",
      "fabriquée\n",
      "par\n",
      "est\n",
      "au\n",
      "__DIGIT__\n",
      "est\n",
      "de\n",
      "à\n",
      "ne\n",
      "afficher\n",
      "de\n",
      "beaucoup\n",
      "plus\n",
      "que\n",
      "M3\n",
      "CSL\n",
      "est\n",
      "de\n",
      "petites\n",
      "arnaques\n",
      "l'\n",
      "et\n",
      "chaque\n",
      "de\n",
      "leur\n",
      "souvenir\n",
      "est\n",
      "cette\n",
      "sur\n",
      "cette\n",
      "Conséquence\n",
      "ayant\n",
      "un\n",
      "une\n",
      "et\n",
      "dans\n",
      "trois\n",
      "des\n",
      "ce\n",
      "qui\n",
      "se\n",
      "garants\n",
      "contient\n",
      "qu'\n",
      "on\n",
      "prête\n",
      "de\n",
      "tout\n",
      "le\n",
      "le\n",
      "Le\n",
      "est\n",
      "chant\n",
      "McQuaid\n",
      "et\n",
      "Le\n",
      "un\n",
      "et\n",
      "été\n",
      "au\n",
      "dès\n",
      "que\n",
      "y\n",
      "suis\n",
      "se\n",
      "du\n",
      "__DIGIT__\n",
      "est\n",
      "maintenant\n",
      "d'\n",
      "empêcher\n",
      "des\n",
      "de\n",
      "de\n",
      "s'\n",
      "sur\n",
      "le\n",
      "à\n",
      "mais\n",
      "il\n",
      "finalement\n",
      "un\n",
      "morceau\n",
      "que\n",
      "plus\n",
      "adultes\n",
      "Les\n",
      "Nations\n",
      "Unies\n",
      "une\n",
      "Scellons\n",
      "l'\n",
      "!\n",
      "On\n",
      "un\n",
      "grand\n",
      "d'\n",
      "du\n",
      "sous\n",
      "diverses\n",
      "est\n",
      "une\n",
      "au\n",
      "et\n",
      "un\n",
      "rose\n",
      "au\n",
      "Champagne\n",
      "le\n",
      "surmonté\n",
      "et\n",
      "de\n",
      "chantilly\n",
      "Le\n",
      "a\n",
      "de\n",
      "ses\n",
      "au\n",
      "une\n",
      "en\n",
      "respectant\n",
      "des\n",
      "de\n",
      "sans\n",
      "ni\n",
      "de\n",
      "été\n",
      "des\n",
      "du\n",
      "les\n",
      "sous-espèces\n",
      "été\n",
      "des\n",
      "Le\n",
      "de\n",
      "l'\n",
      "BBox\n",
      "Bouygues\n",
      "a\n",
      "trois\n",
      "au\n",
      "ces\n",
      "et\n",
      "associations\n",
      "des\n",
      "l'\n",
      "comme\n",
      "l'\n",
      "Mission\n",
      "l'\n",
      "des\n",
      "l'\n",
      "Le\n",
      "est\n",
      "au\n",
      "__DIGIT__\n",
      "des\n",
      "et\n",
      "l'\n",
      "__DIGIT__\n",
      "que\n",
      "des\n",
      "deux\n",
      "langues\n",
      "L'\n",
      "Équestre\n",
      "dans\n",
      "__DIGIT__\n",
      "pour\n",
      "Championnats\n",
      "du\n",
      "Monde\n",
      "Candidat\n",
      "à\n",
      "présidentielle\n",
      "néanmoins\n",
      "la\n",
      "République\n",
      "le\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "lorsque\n",
      "est\n",
      "écarté\n",
      "cette\n",
      "par\n",
      "n'\n",
      "de\n",
      "et\n",
      "leurs\n",
      "au\n",
      "été\n",
      "faire\n",
      "un\n",
      "par\n",
      "enfants\n",
      "on\n",
      "y\n",
      "II\n",
      "n'\n",
      "a\n",
      "de\n",
      "front\n",
      "est\n",
      "Elle\n",
      "est\n",
      "par\n",
      "-\n",
      "Ottobre\n",
      "une\n",
      "à\n",
      "non\n",
      "qui\n",
      "conçue\n",
      "comme\n",
      "de\n",
      "et\n",
      "de\n",
      "des\n",
      "n'\n",
      "est\n",
      "douée\n",
      "pour\n",
      "ses\n",
      "ce\n",
      "et\n",
      "ses\n",
      "comme\n",
      "fait\n",
      "elle\n",
      "être\n",
      "comme\n",
      "qui\n",
      "l'\n",
      "premier\n",
      "au\n",
      "l'\n",
      "Mais\n",
      "l'\n",
      "elle-même\n",
      "est\n",
      "un\n",
      "bien\n",
      "qui\n",
      "ne\n",
      "se\n",
      "sur\n",
      "un\n",
      "La\n",
      "de\n",
      "est\n",
      "plus\n",
      "et\n",
      "plus\n",
      "sucrée\n",
      "que\n",
      "fraises\n",
      "de\n",
      "les\n",
      "étaient\n",
      "des\n",
      "à\n",
      "s'\n",
      "et\n",
      "Quelques\n",
      "années\n",
      "plus\n",
      "il\n",
      "d'\n",
      "l'\n",
      "de\n",
      "un\n",
      "afin\n",
      "de\n",
      "les\n",
      "chorégraphie\n",
      "et\n",
      "de\n",
      "leur\n",
      "de\n",
      "l'\n",
      "affirme\n",
      "que\n",
      "pour\n",
      "face\n",
      "à\n",
      "telles\n",
      "en\n",
      "indique\n",
      "un\n",
      "Le\n",
      "lequel\n",
      "explique\n",
      "certaines\n",
      "des\n",
      "que\n",
      "son\n",
      "tant\n",
      "que\n",
      "à\n",
      "L'\n",
      "Antéchrist\n",
      "de\n",
      "dans\n",
      "lequel\n",
      "le\n",
      "la\n",
      "que\n",
      "était\n",
      "fait\n",
      "un\n",
      "similaire\n",
      "au\n",
      "et\n",
      "que\n",
      "christ\n",
      "rien\n",
      "à\n",
      "l'\n",
      "au-delà\n",
      "et\n",
      "de\n",
      "mais\n",
      "du\n",
      "bien\n",
      "ce\n",
      "dans\n",
      "l'\n",
      "à\n",
      "son\n",
      "et\n",
      "est\n",
      "à\n",
      "et\n",
      "épargne\n",
      "ce\n",
      "que\n",
      "l'\n",
      "Le\n",
      "immigrée\n",
      "et\n",
      "les\n",
      "les\n",
      "de\n",
      "et\n",
      "les\n",
      "de\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celle-ci\n",
      "des\n",
      "de\n",
      "est\n",
      "l'\n",
      "Le\n",
      "Journal\n",
      "Hebdomadaire\n",
      "et\n",
      "son\n",
      "__DIGIT__\n",
      "par\n",
      "d'\n",
      "premier\n",
      "Blanche\n",
      "Nord\n",
      "ou\n",
      "des\n",
      "surnom\n",
      "à\n",
      "aux\n",
      "de\n",
      "est\n",
      "un\n",
      "Garges-lès-Gonesse\n",
      "en\n",
      "devenues\n",
      "ou\n",
      "menacées\n",
      "survivent\n",
      "du\n",
      "nunavik\n",
      "à\n",
      "N'\n",
      "quelques\n",
      "est\n",
      "Licencié\n",
      "et\n",
      "géographie\n",
      "à\n",
      "Yale\n",
      "aux\n",
      "été\n",
      "la\n",
      "Le\n",
      "du\n",
      "l'\n",
      "ancienne\n",
      "Signy-le-Petit\n",
      "dont\n",
      "l'\n",
      "à\n",
      "court\n",
      "trois\n",
      "emplois\n",
      "et\n",
      "de\n",
      "faibles\n",
      "altitudes\n",
      "tandis\n",
      "au\n",
      "les\n",
      "vers\n",
      "Le\n",
      "dernier\n",
      "avant\n",
      "l'\n",
      "un\n",
      "ZNIEFF\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "se\n",
      "de\n",
      "professionnels\n",
      "des\n",
      "de\n",
      "jusqu'\n",
      "à\n",
      "__DIGIT__\n",
      "également\n",
      "des\n",
      "et\n",
      "des\n",
      "des\n",
      "Gaulois\n",
      "l'\n",
      "une\n",
      "les\n",
      "du\n",
      "été\n",
      "Cour\n",
      "Bien\n",
      "ait\n",
      "un\n",
      "et\n",
      "nombreuses\n",
      "South\n",
      "plus\n",
      "et\n",
      "et\n",
      "dans\n",
      "arc\n",
      "Les\n",
      "-ils\n",
      "en\n",
      "reconnus\n",
      "et\n",
      "en\n",
      "un\n",
      "Iconographie\n",
      "photographique\n",
      "à\n",
      "__DIGIT__\n",
      "Concert\n",
      "d'\n",
      "est\n",
      "un\n",
      "de\n",
      "baroque\n",
      "__DIGIT__\n",
      "l'\n",
      "son\n",
      "à\n",
      "Comme\n",
      "__DIGIT__\n",
      "le\n",
      "d'\n",
      "le\n",
      "Les\n",
      "ne\n",
      "de\n",
      "en\n",
      "membres\n",
      "par\n",
      "des\n",
      "que\n",
      "se\n",
      "Pour\n",
      "est\n",
      "ou\n",
      "s'\n",
      "est\n",
      "selon\n",
      "à\n",
      "l'\n",
      "agapè\n",
      "été\n",
      "numérique\n",
      "des\n",
      "puis\n",
      "et\n",
      "compositeurs\n",
      "qui\n",
      "à\n",
      "l'\n",
      "ont\n",
      "d'\n",
      "L'\n",
      "du\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "est\n",
      "première\n",
      "pluraliste\n",
      "trois\n",
      "quoique\n",
      "le\n",
      "été\n",
      "aux\n",
      "Une\n",
      "du\n",
      "du\n",
      "des\n",
      "sera\n",
      "à\n",
      "pour\n",
      "du\n",
      "et\n",
      "des\n",
      "prochaines\n",
      "actions\n",
      "à\n",
      "le\n",
      "__DIGIT__\n",
      "__DIGIT__\n",
      "à\n",
      "est\n",
      "une\n"
     ]
    }
   ],
   "source": [
    "print(len(wrong))\n",
    "for w in wrong:\n",
    "    print(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## different orthographic\n",
    "    # banary feature indicating whether the word starts with a capital letter or not, 1:yes, 0:not\n",
    "    res.append(('start_capital',1 if word.istitle() else 0))\n",
    "    # banary feature indicating whether the word is made of all capital letters or not, 1:yes, 0:not\n",
    "    res.append(('only_capital',1 if word.isupper() else 0))\n",
    "    # banary feature indicating whether the word has a digit or not, 1:yes, 0:not\n",
    "    res.append(('has_digit', 1 if has_digit(word) else 0))\n",
    "    # banary feature indicating whether the word has a hyphen or not, 1:yes, 0:not\n",
    "    res.append(('has_hyphen', 1 if '-' in word else 0))\n",
    "    # banary feature indicating whether the word has a low hyphen or not, 1:yes, 0:not\n",
    "    res.append(('has_hyphen_low', 1 if '_' in word else 0))\n",
    "    # banary feature indicating whether the letters in the word are all alphanumeric or not, 1:yes, 0:not\n",
    "    res.append(('isalnum', 1 if word.isalnum() else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
