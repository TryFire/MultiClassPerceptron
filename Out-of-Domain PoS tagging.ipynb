{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = json.load(open('corpus/fr/fr.gsd.train.json'))\n",
    "dev_set = json.load(open('corpus/fr/fr.gsd.dev.json'))\n",
    "test_set = json.load(open('corpus/fr/fr.gsd.test.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a vue on data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Les', 'commotions', 'cérébrales', 'sont', 'devenu', 'si', 'courantes', 'dans', 'ce', 'sport', \"qu'\", 'on', 'les', 'considére', 'presque', 'comme', 'la', 'routine', '.']\n",
      "['DET', 'NOUN', 'ADJ', 'AUX', 'VERB', 'ADV', 'ADJ', 'ADP', 'DET', 'NOUN', 'SCONJ', 'PRON', 'PRON', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
      "[\"L'\", 'œuvre', 'est', 'située', 'dans', 'la', 'galerie', 'des', 'batailles', ',', 'dans', 'le', 'château', 'de', 'Versailles', '.']\n",
      "['DET', 'NOUN', 'AUX', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP+DET', 'NOUN', 'PUNCT', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT']\n",
      "['Le', 'comportement', 'de', 'la', 'Turquie', 'vis-à-vis', 'du', 'problème', 'palestinien', 'a', 'fait', \"qu'\", 'elle', \"n'\", 'est', 'plus', 'en', 'odeur', 'de', 'sainteté', 'auprès', 'de', 'la', 'communauté', 'juive', 'en', 'générale', ',', 'et', 'américaine', 'en', 'particulier', '.']\n",
      "['DET', 'NOUN', 'ADP', 'DET', 'PROPN', 'NOUN', 'ADP+DET', 'NOUN', 'ADJ', 'AUX', 'VERB', 'SCONJ', 'PRON', 'ADV', 'VERB', 'ADV', 'ADP', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'DET', 'NOUN', 'ADJ', 'ADP', 'ADJ', 'PUNCT', 'CCONJ', 'ADJ', 'ADP', 'ADJ', 'PUNCT']\n",
      "['Toutefois', ',', 'les', 'filles', 'adorent', 'les', 'desserts', '.']\n",
      "['ADV', 'PUNCT', 'DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
      "['Ismene', 'entre', 'et', 'annonce', 'que', \"c'\", 'est', 'Farnace', 'qui', 'a', 'mis', 'le', 'feu', 'à', 'la', 'flotte', 'romaine', '.']\n",
      "['PROPN', 'VERB', 'CCONJ', 'VERB', 'SCONJ', 'PRON', 'AUX', 'PROPN', 'PRON', 'AUX', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT']\n",
      "['je', 'reviendrais', 'avec', 'plaisir', '!']\n",
      "['PRON', 'VERB', 'ADP', 'NOUN', 'PUNCT']\n",
      "['Les', 'forfaits', 'comprennent', 'le', 'transport', 'en', 'car', 'Grand', 'Tourisme', 'des', 'différents', 'lieux', 'de', 'départs', 'proposés', 'autour', 'de', 'Lyon', ',', 'le', 'forfait', 'de', 'ski', 'sur', 'le', 'domaine', 'cité', ',', 'un', 'en-cas', 'petit-déjeuner', 'servi', 'à', 'votre', 'arrivée', 'en', 'station', 'et', 'le', 'service', \"d'\", 'un', 'accompagnateur', 'salarié', 'assurant', 'la', 'logistique', 'des', 'départs', 'et', 'des', 'retours', '.']\n",
      "['DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'PROPN', 'ADP+DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'VERB', 'ADP', 'ADP', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'PUNCT', 'DET', 'NOUN', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'CCONJ', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADJ', 'VERB', 'DET', 'NOUN', 'ADP+DET', 'NOUN', 'CCONJ', 'ADP+DET', 'NOUN', 'PUNCT']\n",
      "['Il', 'prévient', 'que', 'de', 'telles', 'agressions', 'sont', '\"', 'susceptibles', \"d'\", 'entraîner', 'des', 'poursuites', 'judiciaires', '\"', '.']\n",
      "['PRON', 'VERB', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'AUX', 'PUNCT', 'ADJ', 'ADP', 'VERB', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'PUNCT']\n",
      "['Ils', 'tiraient', 'à', 'balles', 'réelles', 'sur', 'la', 'foule', '.']\n",
      "['PRON', 'VERB', 'ADP', 'NOUN', 'ADJ', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
      "['Le', 'château', 'est', 'ensuite', 'vendu', 'plusieurs', 'fois', ';']\n",
      "['DET', 'NOUN', 'AUX', 'ADV', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
      "['En', 'effet', ',', 'la', 'biréfringence', \"n'\", 'étant', 'pas', 'visible', ',', 'elle', \"n'\", 'est', 'pas', 'prépondérante', 'sur', 'le', 'pouvoir', 'rotatoire', '.']\n",
      "['ADP', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'ADV', 'AUX', 'ADV', 'ADJ', 'PUNCT', 'PRON', 'ADV', 'AUX', 'ADV', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT']\n",
      "['Le', 'point', 'final', 'de', 'la', 'plate-forme', 'de', 'distribution', 'serait', 'basé', 'en', 'Autriche', 'à', 'Baumgarten', 'pour', 'rejoindre', 'ensuite', 'le', 'réseau', \"d'\", 'Europe', 'centrale', 'et', 'de', \"l'\", 'ouest', '.']\n",
      "['DET', 'NOUN', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'AUX', 'VERB', 'ADP', 'PROPN', 'ADP', 'PROPN', 'ADP', 'VERB', 'ADV', 'DET', 'NOUN', 'ADP', 'PROPN', 'ADJ', 'CCONJ', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
      "[\"L'\", 'information', 'génétique', 'est', 'codée', 'sous', 'forme', \"d'\", 'ADN', '.']\n",
      "['DET', 'NOUN', 'ADJ', 'AUX', 'VERB', 'ADP', 'NOUN', 'ADP', 'NOUN', 'PUNCT']\n",
      "['Motivé', 'par', 'la', 'charité', 'chrétienne', ',', 'la', 'communauté', 'a', 'changé', 'un', 'vieil', 'immeuble', 'abanbonné', 'où', 'se', 'pratiquaient', \"d'\", 'ailleurs', 'de', 'nombreux', 'échanges', 'de', 'drogues', 'en', 'ce', 'logement', 'sûr', ',', 'propre', 'et', 'abordable', \"qu'\", 'il', 'est', \"aujourd'hui\", '.']\n",
      "['VERB', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'DET', 'NOUN', 'AUX', 'VERB', 'DET', 'ADJ', 'NOUN', 'VERB', 'ADV', 'PRON', 'VERB', 'ADP', 'ADV', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'ADJ', 'CCONJ', 'ADJ', 'PRON', 'PRON', 'AUX', 'ADV', 'PUNCT']\n",
      "['Il', 'exploitait', 'un', 'site', 'de', 'haute', 'valeur', 'militaire', 'et', 'commerciale', 'comprenant', 'un', 'surplomb', 'rocheux', 'dominant', 'en', 'à-pic', 'la', 'rivière', 'Oust', '.']\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADJ', 'CCONJ', 'ADJ', 'VERB', 'DET', 'NOUN', 'ADJ', 'VERB', 'ADP', 'NOUN', 'DET', 'NOUN', 'PROPN', 'PUNCT']\n",
      "['Plus', 'tard', 'dans', 'la', 'saison', ',', 'ils', 'consomment', 'beaucoup', 'de', 'baies', 'et', 'autres', 'petits', 'fruits', '.']\n",
      "['ADV', 'ADV', 'ADP', 'DET', 'NOUN', 'PUNCT', 'PRON', 'VERB', 'ADV', 'ADP', 'NOUN', 'CCONJ', 'ADJ', 'ADJ', 'NOUN', 'PUNCT']\n",
      "['Ils', 'deviennent', 'alors', 'les', 'Paladins', ',', 'chevaliers', 'du', 'bien', 'chargés', 'de', 'défendre', 'élèves', 'et', 'professeurs', '.']\n",
      "['PRON', 'VERB', 'ADV', 'DET', 'PROPN', 'PUNCT', 'NOUN', 'ADP+DET', 'NOUN', 'VERB', 'ADP', 'VERB', 'NOUN', 'CCONJ', 'NOUN', 'PUNCT']\n",
      "['Le', 'chevalier', 'lui', 'propose', 'une', 'partie', \"d'\", 'échecs', ',', 'espérant', 'retarder', \"l'\", 'échéance', 'fatidique', ',', 'le', 'temps', 'de', 'trouver', 'une', 'solution', 'à', 'ses', 'problèmes', 'métaphysiques', ':', 'Dieu', 'existe', '-il', '?']\n",
      "['DET', 'NOUN', 'PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'PUNCT', 'VERB', 'VERB', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'DET', 'NOUN', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADJ', 'PUNCT', 'PROPN', 'VERB', 'PRON', 'PUNCT']\n",
      "['Créée', 'au', 'cours', 'du', 'troisième', 'trimestre', '__DIGIT__', 'comme', 'escadrille', 'MF', '__DIGIT__', ',', 'elle', 'a', 'disparu', 'en', 'même', 'temps', 'que', 'la', '30e', 'Escadre', 'de', 'Chasse', 'à', 'laquelle', 'elle', 'était', 'intégrée', '.']\n",
      "['VERB', 'ADP+DET', 'NOUN', 'ADP+DET', 'ADJ', 'NOUN', 'NUM', 'ADP', 'NOUN', 'PROPN', 'PROPN', 'PUNCT', 'PRON', 'AUX', 'VERB', 'ADP', 'ADJ', 'NOUN', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADP', 'PRON', 'PRON', 'AUX', 'ADJ', 'PUNCT']\n",
      "['On', 'ne', 'peut', 'éviter', 'de', 'penser', 'à', \"l'\", 'actualité', 'caractérisée', 'par', \"l'\", 'enlèvement', 'des', 'otages', 'au', 'Niger', '--', 'dont', 'cinq', 'Français', '.']\n",
      "['PRON', 'ADV', 'VERB', 'VERB', 'ADP', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP+DET', 'NOUN', 'ADP+DET', 'PROPN', 'PUNCT', 'PRON', 'NUM', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "for k,v in train_set[:20]:\n",
    "    print(k)\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing shortly the different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbr of train_set : 14450\n",
      "nbr of dev_set : 1476\n",
      "nbr of test_set : 416\n"
     ]
    }
   ],
   "source": [
    "# the data may be come from the newspaper\n",
    "\n",
    "# the number of sentences in each data_set\n",
    "print('nbr of sentences in train_set : %d'% len(train_set))\n",
    "print('nbr of sentences in dev_set : %d'% len(dev_set))\n",
    "print('nbr of sentences in test_set : %d'% len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three measures of the noisiness of a corpus\n",
    "\n",
    "- The percentage of **Out-of-Vocabulary (OOV) words**, i.e. words appearing in the test set that are not contained on the train set;\n",
    "- **[The KL divergence of 3-grams characters](https://aclweb.org/anthology/W16-3905)** distributions estimated on the train and test sets\n",
    "- perplexity on the test set of a (word level) Language Model estimated on the test\n",
    "set. The language model can be estimated by KenLM (this tools can also be used\n",
    "to compute the perpexlity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(data_set):\n",
    "    '''\n",
    "    data_set : input data in dimension of (N,M)\n",
    "    \n",
    "    return : the set of words appearing the data_set\n",
    "    '''\n",
    "    words = set()\n",
    "    for k,v in data_set:\n",
    "        words = words.union(k)\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The percentage of Out-of-Vocabulary (OOV) words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_train_set = extract_words(train_set)\n",
    "words_test_set = extract_words(test_set)\n",
    "oov = words_test_set.difference(words_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of oov in train_set : 1.38%\n",
      "percentage of oov in test_set : 17.84%\n"
     ]
    }
   ],
   "source": [
    "print('percentage of oov in train_set : %.2f%%'%(len(oov)/len(words_train_set)*100))\n",
    "print('percentage of oov in test_set : %.2f%%'%(len(oov)/len(words_test_set)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:// The KL divergence of 3-grams characters distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we try to mesure the noisiness of a corpus, because the noisiness can do large impact on the performance of model. And a good knowledge can help us to build and train a better model.\n",
    "- here the metric gives a low value means that there are few noisiness in the corpus, else much noisiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:// compute the value of the different metric for the different combination of train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### Considering the features\n",
    "\n",
    "- **the word**  *explain : this feature can directly get the labels which are related to the word*\n",
    "#### *Windows*\n",
    "- **a window of 5 words around the word** of interest (i.e. the word we want to predict a label for, the two previous words and the two following words) *explain: these features can make the label more accurate*\n",
    "#### *Word features*\n",
    "In this section, we consider these sources of information equally important and normalize each of the four component vectors to unit length\n",
    "- **counts of left neighbors**\n",
    "- **counts of right neighbors**\n",
    "- **binary suffix features**\n",
    "- **binary shape features**\n",
    "#### *Distributional features*\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
